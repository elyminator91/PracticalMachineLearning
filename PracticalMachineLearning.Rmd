---
title: "PracticalMachineLearning"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary
This study seeks to predict the manner in which the subjects did the exercise. Random forest model is found to have better prediction capability and hence used in favour of decision tree classification model.

## Getting and Cleaning Data
```{r, message=FALSE}
# load required library
library(dplyr)
library(caret)
```

**DATA SOURCE**
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. <a href="http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201">Qualitative Activity Recognition of Weight Lifting Exercises</a>. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
```{r}
# load training data
if(!file.exists("./pml-training.csv")){
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
                destfile = "./pml-training.csv")
}

train <- read.csv("./pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
dim(train)

# remove columns containing more than 95% of NA values
nas95 <- sapply(train, function(x) (sum(is.na(x))/length(x) <= 0.95))
train <- train[nas95]
dim(train)
```

```{r}
# load test data
if(!file.exists("./pml-test.csv")){
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
                destfile = "./pml-test.csv")
}

test <- read.csv("./pml-test.csv", na.strings = c("NA", "#DIV/0!", ""))
dim(test)

# clean test data by removing the same columns per train data
test <- test[nas95]
dim(test)
```


## Cross Validation
To cross validate the model, the `TRAIN` dataset is divided into 70-30 proportion. The 70% subset will be used to train the model whereas the 30% subset will be used for cross validation.
```{r}
# split train data into 70-30 portions for cross validation
set.seed(10)
inTrain <- createDataPartition(y = train$classe, p = 0.7, list = FALSE)
training <- train[inTrain, ]
testing <- train[-inTrain, ]
```

## Model 1: Decision Trees
```{r}
# first 7 columns of train data containing X, username, timestamp, window are removed
# to prevent interference
mdl1 <- rpart::rpart(classe ~ ., method = "class", data = training[-c(1:7)])
rattle::fancyRpartPlot(mdl1)

testing_prediction <- predict(mdl1, newdata = testing, type = "class")
confusionMatrix(testing_prediction, testing$classe)
```

The decision tree model predicts the manner in which the subject exercise with accuracy of `r round(confusionMatrix(testing_prediction, testing$classe)[[3]][1] * 100, 2)`%.

## Model 2: Random Forest
```{r}
mdl2 <- randomForest::randomForest(classe ~ ., data = training[-c(1:7)])
mdl2

testing_prediction <- predict(mdl2, newdata = testing, type = "class")
confusionMatrix(testing_prediction, testing$classe)
```

The random forest model predicts the manner in which the subject exercise with accuracy of `r round(confusionMatrix(testing_prediction, testing$classe)[[3]][1] * 100, 2)`%.

## Model Selection
Given the higher accuracy of the random forest model, we will use the model in favour of the classification model to predict the test dataset.
```{r}
prediction <- predict(mdl2, newdata = test, type = "class")
prediction
table(prediction)
```

